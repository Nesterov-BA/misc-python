{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f18a5db-39f3-4e39-a407-3a8e62c725ce",
   "metadata": {},
   "source": [
    "# Классификация заемщиков линейными моделями\n",
    "\n",
    "## курс \"Машинное обучение 1\", программа AIMasters, 2024\n",
    "\n",
    "## Студент: Нестеров Борис Аркадьевич"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a231007",
   "metadata": {},
   "source": [
    "## Реализация алгоритмов (5 баллов)\n",
    "\n",
    "Ниже нужно написать собственную реализацию линейного классификатора с произвольной функцией потерь и реализацию функции и градиента функции потерь для логистической регрессии. Реализации можно частично проверить через юнит тесты. В этом блоке можно использовать только `numpy, scipy`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f876778",
   "metadata": {},
   "source": [
    "В `BinaryLogisticLoss` вам нужно реализовать расчет лосса и его градиента для функции \n",
    "$$L(w) = \\frac{1}{N} \\sum_{N} [\\log(1 + \\exp(-y_i\\langle w, x_i\\rangle))] + \\lambda \\lVert w \\rVert^2_2, \\quad y \\in \\{-1, 1\\}$$\n",
    "\n",
    "- `func(self, X, y, w)` — вычисление значения функции потерь на матрице признаков X, векторе ответов y с вектором весов w.\n",
    "- `grad(self, X, y, w)` — вычисление значения градиента функции потерь на матрице признаков X, векторе ответов y с вектором весов w.\n",
    "\n",
    "У обоих методов одинаковые аргументы:\n",
    "- X - выборка объектов\n",
    "- y - вектор ответов\n",
    "- w - вектор коэффициентов модели\n",
    "\n",
    "Вектор коэффициентов имеет вид: w = `[bias, weights]`, то есть нулевой элемент w - `bias`, остальное - веса, участвующие в скалярном произведении. **Важно:** `bias` не участвует в расчете слагаемого с $\\lambda$.\n",
    "\n",
    "Обратите внимание, что на матрица X на входе без столбца с 1 в начале. Пример изменения Х внутри кода функций:\n",
    "```python\n",
    "X_new = np.c_[np.ones(X.shape[0]), X]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4053523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.special import expit\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "class BinaryLogisticLoss():\n",
    "    \"\"\"\n",
    "    Loss function for binary logistic regression.\n",
    "    It should support l2 regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, l2_coef):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        l2_coef - l2 regularization coefficient\n",
    "        \"\"\"\n",
    "        self.l2_coef = l2_coef\n",
    "\n",
    "    def func(self, X, y, w):\n",
    "        \"\"\"\n",
    "        Get loss function value for data X, target y and coefficient w; w = [bias, weights].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray\n",
    "        y : 1d numpy.ndarray\n",
    "        w : 1d numpy.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        : float\n",
    "        \"\"\"\n",
    "        l2Reg  = np.linalg.norm(self.l2_coef * w[1:],2) \n",
    "        l2Reg = l2Reg**2\n",
    "        \n",
    "        X_new = np.c_[np.ones(X.shape[0]), X]\n",
    "        loss = np.logaddexp(0,-y*np.matmul(X_new,w))\n",
    "        loss = np.average(loss)\n",
    "        return loss + l2Reg\n",
    "\n",
    "\n",
    "    def grad(self, X, y, w):\n",
    "        \"\"\"\n",
    "        Get loss function gradient for data X, target y and coefficient w; w = [bias, weights].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray\n",
    "        y : 1d numpy.ndarray\n",
    "        w : 1d numpy.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        : 1d numpy.ndarray\n",
    "        \"\"\"\n",
    "        gradReg = 2 * self.l2_coef * w\n",
    "        gradReg[0] = 0  \n",
    "\n",
    "        X_new = np.c_[np.ones(X.shape[0]), X]\n",
    "        sigmoid = expit(-y * np.dot(X_new, w))\n",
    "        grad = np.dot(X_new.T, -y * sigmoid) / X.shape[0]\n",
    "        grad += gradReg\n",
    "\n",
    "        return grad\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc060bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = BinaryLogisticLoss(l2_coef=1.0)\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [-5, 6]\n",
    "])\n",
    "y = np.array([-1, 1, 1])\n",
    "w = np.array([1, 2, 3])\n",
    "assert np.isclose(loss_function.func(X, y, w), 16.00008, atol=1e-5)\n",
    "\n",
    "loss_function = BinaryLogisticLoss(l2_coef=0.0)\n",
    "X = np.array([\n",
    "    [10 ** 5],\n",
    "    [-10 ** 5],\n",
    "    [10 ** 5]\n",
    "])\n",
    "y = np.array([1, -1, 1])\n",
    "w = np.array([1, 100])\n",
    "assert np.isclose(loss_function.func(X, y, w), 0, atol=1e-5)\n",
    "\n",
    "loss_function = BinaryLogisticLoss(l2_coef=0.0)\n",
    "X = np.array([\n",
    "    [10 ** 2],\n",
    "    [-10 ** 2],\n",
    "    [10 ** 2]\n",
    "])\n",
    "y = np.array([-1, 1, -1])\n",
    "w = np.array([1, 100])\n",
    "assert np.isclose(loss_function.func(X, y, w), 10000.333334, atol=1e-5)\n",
    "\n",
    "loss_function = BinaryLogisticLoss(l2_coef=1.0)\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [-5, 6]\n",
    "])\n",
    "y = np.array([-1, 1, 1])\n",
    "w = np.array([1, 2, 3])\n",
    "right_gradient = np.array([0.33325, 4.3335 , 6.66634])\n",
    "assert np.isclose(loss_function.grad(X, y, w), right_gradient, atol=1e-5).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b94c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18d5de80",
   "metadata": {},
   "source": [
    "В `LinearModel` нужно реализовать линейную модель, поддерживающей обучение через стохастический градиентные спуск.\n",
    "\n",
    "`__init__` — инициализатор класса с параметрами:\n",
    "- loss_function — функция потерь, заданная классом\n",
    "- batch_size — размер подвыборки, по которой считается градиент\n",
    "- step_alpha — параметр шага градиентного спуска \n",
    "- tolerance — критерий останова метода — модуль разности значений функции потерь на соседних итерациях метода меньше tolerance, не весов.\n",
    "- max_iter — максимальное число итераций (эпох)\n",
    "\n",
    "`fit(self, X, y, w_0=None)` — обучение линейной модели\n",
    "\n",
    "- X — выборка объектов\n",
    "- y — вектор ответов\n",
    "- w_0 — начальное приближение вектора коэффициентов, если None, то необходимо инициализировать внутри метода. w_0 имеет вид `[bias_0, weights_0]`.\n",
    "\n",
    "`predict_proba(self, X)` — получение вероятностей для 2х классов\n",
    "- X — выборка объектов\n",
    "\n",
    "Вы можете поменять формат изменения шага градиентного спуска, по дефолту предполагается, что можно использовать просто `step_alpha`.\n",
    "\n",
    "Про sgd: нет необходимости проводить честное семплирование для каждого батча в методе стохасического градиентного спуска. Вместо этого предлагается в начале одной эпохи сгенерировать случайную перестановку индексов объектов, а затем последовательно выбирать объекты для нового батча из элементов этой перестановки. Псевдокод:\n",
    "```python\n",
    "epoch_rand_indexes = np.random.permutation(X.shape[0])\n",
    "inner_cycle_length = int(np.ceil(X.shape[0] / self.batch_size))\n",
    "\n",
    "for i in range(inner_cycle_length):\n",
    "    start_index = self.batch_size * i\n",
    "    finish_index = self.batch_size * (i + 1)\n",
    "    batch_indexes = epoch_rand_indexes[start_index:finish_index]\n",
    "    # тут считаем градиент только по batch_indexes\n",
    "```\n",
    "\n",
    "Еще несколько советов:\n",
    "\n",
    "В промежуточных вычислениях стоит избегать вычисления $exp(−y_i⟨x_i,w⟩)$, иначе может произойти переполнение.\n",
    "Вместо этого следует напрямую вычислять необходимые величины с помощью специализированных для этого функций: `np.logaddexp, scipy.special.logsumexp и scipy.special.expit`. В ситуации, когда вычисления экспоненты обойти не удаётся, можно воспользоваться процедурой «клипинга» (функция `numpy.clip`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78a3d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class LinearModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss_function,\n",
    "        batch_size=100,\n",
    "        step_alpha=1,\n",
    "        tolerance=1e-5,\n",
    "        max_iter=1000,\n",
    "        random_seed=0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss_function : BaseLoss inherited instance\n",
    "            Loss function to use\n",
    "        batch_size : int\n",
    "        step_alpha : float\n",
    "        tolerance : float\n",
    "            Tolerace for stop criterio.\n",
    "        max_iter : int\n",
    "            Max amount of epoches in method.\n",
    "        \"\"\"\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "        self.step_alpha = step_alpha\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    def fit(self, X, y, w_0=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray or scipy.sparse.csr_matrix\n",
    "            2d matrix, training set.\n",
    "        y : numpy.ndarray\n",
    "            1d vector, target values.\n",
    "        w_0 : numpy.ndarray\n",
    "            1d vector in binary classification.\n",
    "            Initial approximation for SGD method - [bias, weights]\n",
    "        \"\"\"\n",
    "            \n",
    "        if w_0 is None:\n",
    "            w_k = np.zeros(X.shape[1] + 1) # [bias, weights]\n",
    "        else:\n",
    "            w_k = w_0\n",
    "\n",
    "        last_loss = 10**5\n",
    "        for epoch in range(self.max_iter):\n",
    "            epoch_rand_indices = np.random.permutation(X.shape[0])\n",
    "            inner_cycle_length = int(np.ceil(X.shape[0] / self.batch_size))\n",
    "\n",
    "            for i in range(inner_cycle_length):\n",
    "                start_index = self.batch_size * i\n",
    "                finish_index = self.batch_size * (i + 1)\n",
    "                batch_indices = epoch_rand_indices[start_index:finish_index]\n",
    "\n",
    "                X_batch = X[batch_indices]\n",
    "                y_batch = y[batch_indices]\n",
    "\n",
    "                gradient = self.loss_function.grad(X_batch, y_batch, w_k)\n",
    "                w_k -= self.step_alpha*gradient\n",
    "\n",
    "            loss = self.loss_function.func(X, y, w_k)\n",
    "\n",
    "            if (abs(last_loss - loss) < self.tolerance):\n",
    "                print(\"Converged at epoch:\", epoch,\"\\n\")\n",
    "                break\n",
    "            last_loss = loss\n",
    "\n",
    "        self.w = w_k\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray or scipy.sparse.csr_matrix\n",
    "            2d matrix, test set.\n",
    "        Returns\n",
    "        -------\n",
    "        : numpy.ndarray\n",
    "            probs, shape=(X.shape[0], 2)\n",
    "        \"\"\"\n",
    "\n",
    "        X_new = np.c_[np.ones(X.shape[0]), X]\n",
    "        probs = expit(X_new.dot(self.w))\n",
    "        return np.vstack([1 - probs, probs]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc7f2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at epoch: 24 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обратите внимание, что тут достаточно простой тест\n",
    "# ниже еще есть проверка для данных из data\n",
    "X1 = np.random.randint(1, 4, (1000, 10))\n",
    "X2 = np.random.randint(-4, 0, (1000, 10))\n",
    "X = np.vstack((X1, X2))\n",
    "y = np.array([-1] * 1000 + [1] * 1000)\n",
    "loss_function = BinaryLogisticLoss(l2_coef=0.1)\n",
    "linear_model = LinearModel(\n",
    "    loss_function=loss_function,\n",
    "    batch_size=100,\n",
    "    step_alpha=1,\n",
    "    tolerance=1e-4,\n",
    "    max_iter=1000,\n",
    ")\n",
    "linear_model.fit(X, y)\n",
    "prediction_probs = linear_model.predict_proba(X)\n",
    "predictions = (prediction_probs > 0.5).astype('int')[:, 1] * 2 - 1\n",
    "assert np.isclose(predictions, y).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60631bb",
   "metadata": {},
   "source": [
    "## Эксперименты (5 баллов)\n",
    "\n",
    "Эксперименты будем проводить на [датасете](https://www.kaggle.com/competitions/home-credit-default-risk/overview) по классификации заемщиков на плохих (target = 1: клиент с \"payment difficulties\") и хороших (target = 0: все остальные). Для экспериментов будем использовать лишь основной файл `application_train.csv`, а также перекодируем таргет в метки -1, 1.\n",
    "\n",
    "Описание колонок находится в файле `description.csv`.\n",
    "\n",
    "Для начала мы за вас считаем данные и поделим на обучение и тест.\n",
    "\n",
    "Код в чтение, разбиение и предобработке менять не нужно.\n",
    "\n",
    "Выполняя задания, не забывайте про [устав](https://t.me/c/2206639786/270/271)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033d5b6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'application_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m col_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m data\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'application_train.csv'"
     ]
    }
   ],
   "source": [
    "# не меняем код\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 150\n",
    "\n",
    "\n",
    "data = pd.read_csv('application_train.csv')\n",
    "data.columns = [\n",
    "    '_'.join([word.lower() for word in col_name.split(' ') if word != '-']) for col_name in data.columns\n",
    "]\n",
    "data.target = data.target.map({0: -1, 1: 1})\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tst shape: (92221, 122)\n",
      "tr shape: (215290, 122)\n"
     ]
    }
   ],
   "source": [
    "# не меняем код\n",
    "test_idx = data.sk_id_curr % 10 >= 7\n",
    "data_dict = dict()\n",
    "data_dict['tst'] = data.loc[test_idx].reset_index(drop=True)\n",
    "data_dict['tr'] = data.loc[~test_idx].reset_index(drop=True)\n",
    "\n",
    "for key, df in data_dict.items():\n",
    "    print(key, 'shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# не меняем код\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "features = data.select_dtypes(np.number).drop(columns=['target', 'sk_id_curr']).columns\n",
    "\n",
    "X_tr, X_tst = data_dict[\"tr\"][features].to_numpy(), data_dict[\"tst\"][features].to_numpy()\n",
    "y_tr, y_tst = data_dict[\"tr\"][\"target\"].to_numpy(), data_dict[\"tst\"][\"target\"].to_numpy()\n",
    "\n",
    "\n",
    "prep = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "prep.fit(X_tr)\n",
    "\n",
    "X_tr = prep.transform(X_tr)\n",
    "X_tst = prep.transform(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151e404",
   "metadata": {},
   "source": [
    "Инициализируйте написанный выше лосс и классификатор, для `BinaryLogisticLoss` возьмите параметр `l2_coef=0.1`, параметры `LinearModel` нужно подобрать так, чтобы [roc_auc_score](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.roc_auc_score.html) был больше 0.72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b42d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = BinaryLogisticLoss(...)\n",
    "clf = LinearModel(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ce492",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "assert roc_auc_score(y_tst, clf.predict_proba(X_tst)[:, 1]) > 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2370009",
   "metadata": {},
   "source": [
    "Ура! Ваша модель что-то может :)\n",
    "\n",
    "Теперь нужно поисследовать реализацию [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html) в sklearn.\n",
    "\n",
    "Сравните различные `solver` по времени обучения/качеству на тесте. Напишите выводы.\n",
    "\n",
    "Выбейте на тесте больше `0.737` roc_auc_score.\n",
    "Для поиска лучшей модели можно использовать:\n",
    "- optuna\n",
    "- [GridSearchCV](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- свои наблюдения и интуицию\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c904ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert roc_auc_score(y_tst, clf.predict_proba(X_tst)[:, 1]) > 0.737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3df2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11864028",
   "metadata": {},
   "source": [
    "Нарисуйте график `feature - weight`, показывающий `top_k` (на ваш выбор) признаков по модулю веса и их значения весов. <br>\n",
    "Признаки должны идти по убыванию модуля веса. <br>\n",
    "Лучше использовать [barplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) или аналоги из других библиотек. <br>\n",
    "Опишите наблюдения, используя описания признаков в `description.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5248f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш график"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70115ac5",
   "metadata": {},
   "source": [
    "Выведите топ признаков с наибольшим/наименьшим абсолютным весом.<br>\n",
    "Опишите наблюдения (ответьте на вопрос: правда ли, что если признак `X` больше/меньше, то вероятность дефолта клиента выше/ниже?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a17c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод топ фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f6ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
